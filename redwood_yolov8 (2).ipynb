{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76wBZQvbeJSx"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics roboflow\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-41TYi8eL7u",
        "outputId": "4e8cd9c3-c702-4caa-b231-d7b9227287b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_path = \"/content/drive/MyDrive/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-TdYOsbSoDCI"
      },
      "outputs": [],
      "source": [
        "yaml_config = \"\"\"\n",
        "path: {project_path}\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: 1\n",
        "names: [\"redwood\"]\n",
        "\"\"\".format(project_path=project_path)\n",
        "\n",
        "with open(\"config.yaml\", \"w\") as f:\n",
        "    f.write(yaml_config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==1.3.1 --quiet\n",
        "import cv2, os\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "img_dir = project_path + \"/images/train\"\n",
        "label_dir = project_path + \"/labels/train\"\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.2),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Rotate(limit=20, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2,\n",
        "                       rotate_limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.0, min_area=1e-6))\n",
        "\n",
        "num_aug = 5\n",
        "\n",
        "def clip_yolo_bbox(bbox):\n",
        "    x, y, w, h = bbox\n",
        "    x_min = max(0.0, x - w/2)\n",
        "    y_min = max(0.0, y - h/2)\n",
        "    x_max = min(1.0, x + w/2)\n",
        "    y_max = min(1.0, y + h/2)\n",
        "    x_new = (x_min + x_max) / 2\n",
        "    y_new = (y_min + y_max) / 2\n",
        "    w_new = x_max - x_min\n",
        "    h_new = y_max - y_min\n",
        "    return [x_new, y_new, w_new, h_new]\n",
        "\n",
        "def filter_valid_bboxes(bboxes, classes, min_size=1e-6):\n",
        "    valid_bboxes = []\n",
        "    valid_classes = []\n",
        "    for bbox, cls in zip(bboxes, classes):\n",
        "        _, _, w, h = bbox\n",
        "        if w > min_size and h > min_size:\n",
        "            valid_bboxes.append(bbox)\n",
        "            valid_classes.append(cls)\n",
        "    return valid_bboxes, valid_classes\n",
        "\n",
        "for img_file in os.listdir(img_dir):\n",
        "    if not img_file.endswith(\".jpg\"):\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(img_dir, img_file)\n",
        "    label_path = os.path.join(label_dir, img_file.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        continue\n",
        "\n",
        "    image = cv2.imread(img_path)\n",
        "\n",
        "    bboxes, class_labels = [], []\n",
        "    with open(label_path) as f:\n",
        "        for line in f:\n",
        "            cls, x, y, bw, bh = map(float, line.split())\n",
        "            bboxes.append([x, y, bw, bh])\n",
        "            class_labels.append(int(cls))\n",
        "\n",
        "    bboxes = [clip_yolo_bbox(b) for b in bboxes]\n",
        "\n",
        "    for i in range(num_aug):\n",
        "        try:\n",
        "            augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        aug_img = augmented['image']\n",
        "        aug_bboxes, aug_classes = filter_valid_bboxes(augmented['bboxes'], augmented['class_labels'])\n",
        "\n",
        "        if len(aug_bboxes) == 0:\n",
        "            continue\n",
        "\n",
        "        aug_img_name = img_file.replace(\".jpg\", f\"_aug{i}.jpg\")\n",
        "        cv2.imwrite(os.path.join(img_dir, aug_img_name), aug_img)\n",
        "\n",
        "        aug_label_name = aug_img_name.replace(\".jpg\", \".txt\")\n",
        "        with open(os.path.join(label_dir, aug_label_name), \"w\") as f:\n",
        "            for cls, (x, y, bw, bh) in zip(aug_classes, aug_bboxes):\n",
        "                f.write(f\"{cls} {x} {y} {bw} {bh}\\n\")"
      ],
      "metadata": {
        "id": "J5RljKlp-R_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_1WHsZ3rGKJ"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "model.train(\n",
        "    data=\"config.yaml\",\n",
        "    epochs=20,\n",
        "    imgsz=416,\n",
        "    batch=16,\n",
        "    project=\"redwood_detection\",\n",
        "    workers=2,\n",
        "    cache=True,\n",
        "    name=\"yolov8n_redwood\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7Cqs04ntEjR"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/redwood_detection/yolov8n_redwood8/weights/best.pt\")\n",
        "results = model.predict(source=\"/content/drive/MyDrive/dataset/images/train\", imgsz=640, conf=0.25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5VTFlpIrxRj"
      },
      "outputs": [],
      "source": [
        "metrics = model.val()\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq5byqLgrzDj"
      },
      "outputs": [],
      "source": [
        "results = model.predict(source=f\"{project_path}/images/val\", save=True, conf=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IvWWp4Hr1sU"
      },
      "outputs": [],
      "source": [
        "model.export(format=\"onnx\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}